{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Hierarchical Organization of Patent Data\n",
    "\n",
    "#### Project Summary\n",
    "While search engines offer a convenient way to search patents, patent data stored in large CSV files often occupy a significant amount of disk space and contain a significant amount of text, oftentimes metadata that seems esoteric to novice users and cannot be easily incorporated into machine learning models. One such example is using the International Patent Classification (IPC) alphabetical nomenclature; while this alphanumeric system effectively categorizes the field of a patent, it would be more helpful to explicitly specify the field and to partition the data based on such field(s), e.g., chemistry and physics patents. \n",
    "\n",
    "The following project is a data pipeline that aims to facilitate patent data organization and storage. Specifically, a Kaggle patent dataset is stored in a public S3 bucket; using AWS IAM credentials, combined with PySpark and pandas modules, the data pipeline normalizes the Kaggle patent dataset (see below), maps the IPC classification using a manually annotated IPC classification definition set (see below) and organizes the patent entries into parquet files stored on an S3 bucket. The final product is a paritioned dataset that can be seamlessly incorporated with big data frameworks such as Hadoop. While beyond the scope of this project, this reorganized and partitioned dataset could greatly facilitate machine learning and natural language processing applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (1.19.1)\n",
      "Requirement already satisfied: pandas==0.25.0 in /opt/conda/lib/python3.6/site-packages (0.25.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas==0.25.0) (2017.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas==0.25.0) (2.6.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from pandas==0.25.0) (1.19.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas==0.25.0) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "#This project requires that the pandas version be at least 0.25.0\n",
    "import sys\n",
    "!{sys.executable} -m pip install s3fs\n",
    "!{sys.executable} -m pip install pandas==0.25.0\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import s3fs \n",
    "import os\n",
    "from  pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, month, dayofmonth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### AWS Credentials\n",
    "Since the Kaggle dataset is stored on a public S3 bucket, there needs to be an IAM Role that permits S3 bucket read access. The access key and secret key are to be entered into the dl.cfg file without any quotation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config=configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS_CREDS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS_CREDS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Sources\n",
    "#### Patent Data Set\n",
    "\n",
    "The first file was obtained from Kaggle in the following repository: https://www.kaggle.com/mystery/patents. \n",
    "\n",
    "This .csv file contains the following fields: \n",
    "- Index: An arbitrary running integer assigned based on the row number.\n",
    "- Application ID: The ID given to an application, which will be assigned by the respective patent & trademark office. This is often used to distinguish international/domestic/patent cooperation treaty (PCT) patents.\n",
    "- Application Number: As with the application id, the application number is a unique identifier for the patent.\n",
    "- Country: The origin of the patent. Patents with the \"WO\" designation signify a PCT application, meaning that is an application valid for multiple countries. \n",
    "- Title: The title of the patent.\n",
    "- Abstract: A general summary of the patent.\n",
    "- International Patent Classification (IPC): An alphanumeric system designed to divide the patent's field into specific categories. While there is a high degree of granularity in this system, the project will only use the most general field.\n",
    "- Application Date: The year in which the patent was first filed for priority date.\n",
    "- Year: The year obtained from the application field\n",
    "- Cluster_tf_idf: An extraneous field that was inherent to the repository.\n",
    "\n",
    "#### IPC Nomenclature\n",
    "The second file creates a mapping system that designates the first letter of the IPC into a general category for the patent's field. The following is an overview of the nomeclature:\n",
    "\n",
    "- A: Human Necessities\n",
    "- B: Performing Operations, Transporting\n",
    "- C: Chemistry, Metallurgy\n",
    "- D: Textiles, Paper\n",
    "- E: Fixed Constructions\n",
    "- F: Mechanical Engineering\n",
    "- G: Physics\n",
    "- H: Electricity\n",
    "\n",
    "These categories can be further sub-categorized based on the numbers that follow the first letter. However, since these numeric values are not annotated into a JSON or CSV file, increasing the granularity of the patent's metadata is beyond the scope of this project. Further information can be found in the link below:\n",
    "\n",
    "https://www.wipo.int/classifications/ipc/ipcpub/?notion=scheme&version=20200101&symbol=none&menulang=en&lang=en&viewmode=f&fipcpc=no&showdeleted=yes&indexes=no&headings=yes&notes=yes&direction=o2n&initial=A&cwid=none&tree=no&searchmode=smart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Read patent dataset from a public S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read data from CSV file into pandas dataframe and remove the index and cluster_tf_idf fields\n",
    "patent_df=pd.read_csv('s3://kaggle-patent-data/Patent_listing.csv')\n",
    "patent_df=patent_df.drop('cluster_tf_idf',1)\n",
    "patent_df.columns=['Index','Application_Id','Application_Number','Country','Title','Abstract','IPC','Application_Date','Year']\n",
    "patent_df=patent_df.drop('Index',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Read IPC annotation dataset from a public S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read data from CSV file into pandas dataframe\n",
    "ipc_df=pd.read_csv('s3://kaggle-patent-data/ipc_classification.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Quality Check\n",
    "The data quality check entails finding potential duplicate values. The unique identifier for the patent is the application id, so this field is used to assess whether or not there is a duplicate entry. The second check is looking for any null/NA values. While the file has been pre-processed, quality control is essential to determine what to do with any such fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect patent dataframe for duplicated data\n",
    "patent_df.duplicated(subset='Application_Id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Application_Id         0\n",
       "Application_Number     2\n",
       "Country                0\n",
       "Title                 18\n",
       "Abstract              23\n",
       "IPC                    0\n",
       "Application_Date       0\n",
       "Year                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect patent dataframe for missing values\n",
    "patent_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Wrangling\n",
    "##### Null Values\n",
    "As shown above, there were null values contained in the dataframe. Since there is only a small percentage of rows with null fields and these fields are essential to the description of the patent, they will not be included in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Application_Id        0\n",
       "Application_Number    0\n",
       "Country               0\n",
       "Title                 0\n",
       "Abstract              0\n",
       "IPC                   0\n",
       "Application_Date      0\n",
       "Year                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_df=patent_df.dropna()\n",
    "patent_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Application_Id</th>\n",
       "      <th>Application_Number</th>\n",
       "      <th>Country</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>IPC</th>\n",
       "      <th>Application_Date</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO2015116015</td>\n",
       "      <td>PCT/UA2014/000017</td>\n",
       "      <td>WO</td>\n",
       "      <td>INFLATABLE AIRCRAFT</td>\n",
       "      <td>inflatable vertical takeoff landing aircraft i...</td>\n",
       "      <td>B64C 29/00; B64C 31/06; B64C 27/32</td>\n",
       "      <td>2014-03-02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO2015166113</td>\n",
       "      <td>PCT/ES2014/070372</td>\n",
       "      <td>WO</td>\n",
       "      <td>SEALING DEVICE FOR AIRCRAFT PROPELLER ENGINE</td>\n",
       "      <td>invention relates sealing device aircraft engi...</td>\n",
       "      <td>B64C 35/00; B64C 11/00; B64C 99/00</td>\n",
       "      <td>2014-04-29</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WO2014185492</td>\n",
       "      <td>PCT/JP2014/062955</td>\n",
       "      <td>WO</td>\n",
       "      <td>VERTICAL TAKE-OFF AND LANDING AIRCRAFT</td>\n",
       "      <td>vertical take landing aircraft comprises prope...</td>\n",
       "      <td>B64C 29/00; B64C 27/20; B64C 27/22</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WO2015112039</td>\n",
       "      <td>PCT/RU2014/000035</td>\n",
       "      <td>WO</td>\n",
       "      <td>AIRCRAFT</td>\n",
       "      <td>﻿ claimed invention relates aviation particula...</td>\n",
       "      <td>B64C 39/12; B64C 11/00; B64C 9/00</td>\n",
       "      <td>2014-01-22</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WO2015099375</td>\n",
       "      <td>PCT/KR2014/012634</td>\n",
       "      <td>WO</td>\n",
       "      <td>MULTI-ROTOR FLYING OBJECT</td>\n",
       "      <td>present invention provides multi rotor flying ...</td>\n",
       "      <td>B64C 27/08; B64C 29/02; B64C 27/52</td>\n",
       "      <td>2014-12-22</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Application_Id Application_Number Country  \\\n",
       "0   WO2015116015  PCT/UA2014/000017      WO   \n",
       "1   WO2015166113  PCT/ES2014/070372      WO   \n",
       "2   WO2014185492  PCT/JP2014/062955      WO   \n",
       "3   WO2015112039  PCT/RU2014/000035      WO   \n",
       "4   WO2015099375  PCT/KR2014/012634      WO   \n",
       "\n",
       "                                          Title  \\\n",
       "0                           INFLATABLE AIRCRAFT   \n",
       "1  SEALING DEVICE FOR AIRCRAFT PROPELLER ENGINE   \n",
       "2        VERTICAL TAKE-OFF AND LANDING AIRCRAFT   \n",
       "3                                      AIRCRAFT   \n",
       "4                     MULTI-ROTOR FLYING OBJECT   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  inflatable vertical takeoff landing aircraft i...   \n",
       "1  invention relates sealing device aircraft engi...   \n",
       "2  vertical take landing aircraft comprises prope...   \n",
       "3  ﻿ claimed invention relates aviation particula...   \n",
       "4  present invention provides multi rotor flying ...   \n",
       "\n",
       "                                  IPC Application_Date  Year  \n",
       "0  B64C 29/00; B64C 31/06; B64C 27/32       2014-03-02  2014  \n",
       "1  B64C 35/00; B64C 11/00; B64C 99/00       2014-04-29  2014  \n",
       "2  B64C 29/00; B64C 27/20; B64C 27/22       2014-05-15  2014  \n",
       "3   B64C 39/12; B64C 11/00; B64C 9/00       2014-01-22  2014  \n",
       "4  B64C 27/08; B64C 29/02; B64C 27/52       2014-12-22  2014  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Multiple IPC Categories\n",
    "While the IPC classification system does offer a good general overview of patent field, there could be instances where a patent can encompass multiple categories. As shown in the dataset above, there are Application Id's that include multiple IPC designations in the \"IPC\" column. While this project only focuses on the first letter and does not account for increased granularity with each subcategory, the data pipeline will assume that the patent could encompass multiple general fields. Thus, the table will be denormalized by exploding the values of the IPC categories into mutliple rows. \n",
    "\n",
    "Based on the structure of the dataset, the data may be split using \"; \" as the delimiter. However, to accomodate for any potential errors in the file structure, the values will be looped through until reaching a letter that falls between \"A\" and \"H\". Through this method, the IPC categories will be mapped to the respect field. For example, an entry such as \"B64C 29/00\" will be mapped to \"Performing Operations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "patent_df['IPC'] = patent_df['IPC'].str.split('; ')\n",
    "patent_df_flattened=patent_df.explode('IPC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Generate an IPC listing and a category listing which will map each IPC category\n",
    "category_listing=[]\n",
    "ipc_list=list(patent_df_flattened.IPC)\n",
    "ipc_list_space_modified = []\n",
    "\n",
    "#Remove any potential leading or trailing whitespaces between each IPC entry\n",
    "for elements in ipc_list:\n",
    "    ipc_list_space_modified.append(elements.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Conver the IPC dataframe into a dictionary that can be used for mapping\n",
    "#Generate a category listing that will then be added into the patents dataframe\n",
    "\n",
    "category_dict=ipc_df.set_index('Section').T.to_dict('list')\n",
    "categories=set(category_dict.keys())\n",
    "\n",
    "for element in ipc_list_space_modified:\n",
    "    try:\n",
    "        category_listing.append((category_dict[element[0]][0]))\n",
    "        \n",
    "    except:\n",
    "        for i in range(0,len(element)):\n",
    "            if element[i] in categories:\n",
    "                category_listing.append(element[i])\n",
    "                break\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "patent_df_flattened['IPC_Description']=pd.Series(category_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Application_Id</th>\n",
       "      <th>Application_Number</th>\n",
       "      <th>Country</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>IPC</th>\n",
       "      <th>Application_Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>IPC_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO2015116015</td>\n",
       "      <td>PCT/UA2014/000017</td>\n",
       "      <td>WO</td>\n",
       "      <td>INFLATABLE AIRCRAFT</td>\n",
       "      <td>inflatable vertical takeoff landing aircraft i...</td>\n",
       "      <td>B64C 29/00</td>\n",
       "      <td>2014-03-02</td>\n",
       "      <td>2014</td>\n",
       "      <td>Performing Operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO2015116015</td>\n",
       "      <td>PCT/UA2014/000017</td>\n",
       "      <td>WO</td>\n",
       "      <td>INFLATABLE AIRCRAFT</td>\n",
       "      <td>inflatable vertical takeoff landing aircraft i...</td>\n",
       "      <td>B64C 31/06</td>\n",
       "      <td>2014-03-02</td>\n",
       "      <td>2014</td>\n",
       "      <td>Performing Operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WO2015116015</td>\n",
       "      <td>PCT/UA2014/000017</td>\n",
       "      <td>WO</td>\n",
       "      <td>INFLATABLE AIRCRAFT</td>\n",
       "      <td>inflatable vertical takeoff landing aircraft i...</td>\n",
       "      <td>B64C 27/32</td>\n",
       "      <td>2014-03-02</td>\n",
       "      <td>2014</td>\n",
       "      <td>Performing Operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO2015166113</td>\n",
       "      <td>PCT/ES2014/070372</td>\n",
       "      <td>WO</td>\n",
       "      <td>SEALING DEVICE FOR AIRCRAFT PROPELLER ENGINE</td>\n",
       "      <td>invention relates sealing device aircraft engi...</td>\n",
       "      <td>B64C 35/00</td>\n",
       "      <td>2014-04-29</td>\n",
       "      <td>2014</td>\n",
       "      <td>Performing Operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WO2015166113</td>\n",
       "      <td>PCT/ES2014/070372</td>\n",
       "      <td>WO</td>\n",
       "      <td>SEALING DEVICE FOR AIRCRAFT PROPELLER ENGINE</td>\n",
       "      <td>invention relates sealing device aircraft engi...</td>\n",
       "      <td>B64C 11/00</td>\n",
       "      <td>2014-04-29</td>\n",
       "      <td>2014</td>\n",
       "      <td>Performing Operations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Application_Id Application_Number Country  \\\n",
       "0   WO2015116015  PCT/UA2014/000017      WO   \n",
       "0   WO2015116015  PCT/UA2014/000017      WO   \n",
       "0   WO2015116015  PCT/UA2014/000017      WO   \n",
       "1   WO2015166113  PCT/ES2014/070372      WO   \n",
       "1   WO2015166113  PCT/ES2014/070372      WO   \n",
       "\n",
       "                                          Title  \\\n",
       "0                           INFLATABLE AIRCRAFT   \n",
       "0                           INFLATABLE AIRCRAFT   \n",
       "0                           INFLATABLE AIRCRAFT   \n",
       "1  SEALING DEVICE FOR AIRCRAFT PROPELLER ENGINE   \n",
       "1  SEALING DEVICE FOR AIRCRAFT PROPELLER ENGINE   \n",
       "\n",
       "                                            Abstract         IPC  \\\n",
       "0  inflatable vertical takeoff landing aircraft i...  B64C 29/00   \n",
       "0  inflatable vertical takeoff landing aircraft i...  B64C 31/06   \n",
       "0  inflatable vertical takeoff landing aircraft i...  B64C 27/32   \n",
       "1  invention relates sealing device aircraft engi...  B64C 35/00   \n",
       "1  invention relates sealing device aircraft engi...  B64C 11/00   \n",
       "\n",
       "  Application_Date  Year        IPC_Description  \n",
       "0       2014-03-02  2014  Performing Operations  \n",
       "0       2014-03-02  2014  Performing Operations  \n",
       "0       2014-03-02  2014  Performing Operations  \n",
       "1       2014-04-29  2014  Performing Operations  \n",
       "1       2014-04-29  2014  Performing Operations  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_df_flattened.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Model\n",
    "Since there are potentially multiple IPC categories for each patent, the dataframe has undergone some degree of denormalization. The schema for the patents datasets entails partitioning the data based on specific fields, i.e., IPC category and country, making a Pyspark dataframe ideal. The dataframe will be converted into a SQL table, which will then be written into parquet datafiles stored in a public S3 bucket of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Convert all dataframe contents into string to ensure proper conversion of pandas dataframe into Pyspark dataframe\n",
    "patent_df_flattened= patent_df_flattened.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark=create_spark_session()\n",
    "\n",
    "spark_patent_df=spark.createDataFrame(patent_df_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create Pyspark data table\n",
    "spark_patent_df.createOrReplaceTempView(\"patents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "patent_data = spark.sql(\"\"\"SELECT  DISTINCT Application_Id as Application_Id,\n",
    "                                            Application_Number as Application_Number,\n",
    "                                            Country as Country,\n",
    "                                            Title as Title,\n",
    "                                            Abstract as Abstract, \n",
    "                                            IPC_Description as IPC_Description,\n",
    "                                            Year as year,\n",
    "                                            month(Application_Date) as month,\n",
    "                                            dayofmonth(Application_Date) as day\n",
    "                           \n",
    "                           FROM patents\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_parquet(pyspark_df, s3_path):\n",
    "    try:\n",
    "        pyspark_df.write.mode(\"overwrite\").partitionBy(\"IPC_Description\",\"Country\").parquet(s3_path)\n",
    "    except:\n",
    "        print(\"There is an error writing parquet file to specific S3 bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3_bucket_path = \".parquet\"\n",
    "\n",
    "write_parquet(patent_data, s3_bucket_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Closing Remarks\n",
    "Patents data is very extensive, and even a relatively small file can be quite cumbersome to organize/query on a relational database. Through this methodology, we create a scalable-friendly storage system that can facilitate data organization and retrieval with big data solutions such as Hadoop. Should this dataset become extensive and receive continual data, this project can easily be incorporated into an Apache Airflow DAG, where we can automate the intervals at which the pipeline operates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
